import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.model_selection import StratifiedKFold
import torch

# -*- coding: utf-8 -*-
"""for-the-next-big-things.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aeSsUD_1nS0UZrPOq4mcp0tsTzGDoWkT

# 데이터 로드
"""

print("data loading")
data_path = './data/'
df = pd.read_csv(f'{data_path}train.csv')

"""# Target 인코딩"""

# target encoding
print("target encoding")
le = preprocessing.LabelEncoder()
le.fit(df.cat3.values)
df.cat3 = le.transform(df.cat3.values)

print(f'le.classes_ | {le.classes_}')

# 맞춰야 하는 target 개수 128

# cat1, cat2 Drop
df = df.drop(['cat1', 'cat2'], axis = 1)

"""# K-Fold

## 상황에 따른 K-Fold 종류
- 데이터들이 독립적이고 동일한 분포를 가진 경우
- - K-Fold
- - Repeated K-Fold 
- - Leave One Out (LOO)
- - Leave P Out (LPO)
- - Shuffle & Split
- 데이터의 분포가 다른 경우
- - **Stratified K-Fold**
- - Stratified Shuffle & Split
- 데이터가 그룹화되어 있는 경우
- - Group K-Fold
- - Leave One Group Out
- - Leave P Groups Out
- 데이터가 시계열 데이터인 경우
- - Time Series Split

### Stratified K-Fold

#### Out of Fold 전략
"""


print("kfold") # 여기까지 함 10월 29일 11:37
# kfold 열 생성

FOLD = 5

df['kfold'] = -1
folds = StratifiedKFold(n_splits=FOLD, random_state=42, shuffle=True)

for i in range(FOLD):
    train_idx, valid_idx = list(folds.split(df.values, df['cat3']))[i]
    valid = df.iloc[valid_idx]
    # df.kfold에 fold 번호
    df.loc[df[df.id.isin(valid.id) == True].index.to_list(), 'kfold'] = i
df

import cv2
from torch.utils.data import Dataset, DataLoader
import os

class CategoryDataset(Dataset):
    def __init__(self, text:np.array, image_path, cats3, tokenizer, feature_extractor, max_len)-> None:
        self.text = text
        self.image_path = image_path
        self.cats3 = cats3
        self.tokenizer = tokenizer
        self.feature_extractor = feature_extractor
        self.max_len = max_len
    def __len__(self):
        return len(self.text)
    def __getitem__(self, item):
        text = str(self.text[item])
        image_path = os.path.join(data_path,str(self.image_path[item])[2:])
        image = cv2.imread(image_path)
        cat3 = self.cats3[item]
        encoding = self.tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=self.max_len,
            return_token_type_ids=False,
            padding = 'max_length',
            truncation = True,
            return_attention_mask=True,
            return_tensors='pt',
        )
        image_feature = self.feature_extractor(images=image, return_tensors="pt")
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'pixel_values': image_feature['pixel_values'][0],
            'cats3': torch.tensor(cat3, dtype=torch.long)
        }

def create_data_loader(df, tokenizer, feature_extractor, max_len, batch_size, shuffle_= False):
    ds = CategoryDataset(
        text=df.overview.to_numpy(),
        image_path = df.img_path.to_numpy(),
        cats3=df.cat3.to_numpy(),
        tokenizer=tokenizer,
        feature_extractor = feature_extractor,
        max_len=max_len
    )
    return DataLoader(
        ds,
        batch_size=batch_size,
        num_workers=4,
        shuffle = shuffle_
    )


from transformers import AutoModel,ViTModel,ViTFeatureExtractor
import torch.nn as nn

class TourClassifier(nn.Module):
    def __init__(self, n_classes3, text_model_name, image_model_name):
        super(TourClassifier, self).__init__()
        self.text_model = AutoModel.from_pretrained(text_model_name).to(device)
        self.image_model = ViTModel.from_pretrained(image_model_name).to(device)
        self.text_model.gradient_checkpointing_enable()  
        self.image_model.gradient_checkpointing_enable()  

        self.drop = nn.Dropout(p=0.1)
    
        def get_cls(target_size):
            return nn.Sequential(
                # text model의 hidden size? 
                # 밑에서 Tensor concat 후 들어오니까 변수명 수정해야겠다.
                # 아니면 위에서 concat하는 과정 붙이면 되겠다
                
                # 1024, 1024
                nn.Linear(self.text_model.config.hidden_size, self.text_model.config.hidden_size),
                
                nn.LayerNorm(self.text_model.config.hidden_size),
                nn.Linear(self.text_model.config.hidden_size, 512), # 512 수정 필요 -> 변수로
                nn.Dropout(p = 0.1),
                nn.ReLU(),
                nn.Linear(512, target_size),
            )
        self.cls3 = get_cls(n_classes3)
        
        
    def forward(self, input_ids, attention_mask, pixel_values):
        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)
        image_output = self.image_model(pixel_values = pixel_values)
        concat_outputs = torch.cat([text_output.last_hidden_state, image_output.last_hidden_state],1)
        #config hidden size 일치해야함
        
        encoder_layer = nn.TransformerEncoderLayer(d_model=self.text_model.config.hidden_size, nhead=8).to(device)
        transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=2).to(device)

        outputs = transformer_encoder(concat_outputs)
        #cls token 
        outputs = outputs[:,0]
        output = self.drop(outputs)
        out3 = self.cls3(output)
        return out3

from sklearn.metrics import f1_score
import time
import math


def calc_tour_acc(pred, label):
    _, idx = pred.max(1)
    
    acc = torch.eq(idx, label).sum().item() / idx.size()[0] 
    x = label.cpu().numpy()
    y = idx.cpu().numpy()
    f1_acc = f1_score(x, y, average='weighted')
    return acc,f1_acc

class AverageMeter(object):
    """Computes and stores the average and current value"""
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count


def asMinutes(s):
    m = math.floor(s / 60)
    s -= m * 60
    return '%dm %ds' % (m, s)


def timeSince(since, percent):
    now = time.time()
    s = now - since
    es = s / (percent)
    rs = es - s
    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))

import torch
import numpy as np
from transformers import AutoTokenizer
import argparse
import random
import torch.optim as optim
from transformers.optimization import get_cosine_schedule_with_warmup
from tqdm import tqdm

def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples,epoch):
    batch_time = AverageMeter()     
    data_time = AverageMeter()      
    losses = AverageMeter()         
    accuracies = AverageMeter()
    f1_accuracies = AverageMeter()
  
    sent_count = AverageMeter()   
    

    start = end = time.time()

    model = model.train()
    correct_predictions = 0
    for step,d in enumerate(data_loader): 
        data_time.update(time.time() - end)
        batch_size = d["input_ids"].size(0) 
        input_ids = d["input_ids"].to(device)
        attention_mask = d["attention_mask"].to(device)
        pixel_values = d['pixel_values'].to(device)
        
        cats3 = d["cats3"].to(device)
        outputs3 = model(
          input_ids=input_ids,
          attention_mask=attention_mask,
          pixel_values=pixel_values
        )
        _, preds = torch.max(outputs3, dim=1)
        
        # loss_fn = nn.CrossEntropyLoss().to(device)

        loss3 = loss_fn(outputs3, cats3)
        loss = loss3
#         loss = loss1 * 0.05 + loss2 * 0.1 + loss3 * 0.85

        correct_predictions += torch.sum(preds == cats3)
        losses.update(loss.item(), batch_size)
        loss.backward()
        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        scheduler.step()
        optimizer.zero_grad()

        batch_time.update(time.time() - end)
        end = time.time()

        sent_count.update(batch_size)
        if step % 200 == 0 or step == (len(data_loader)-1):
            acc,f1_acc = calc_tour_acc(outputs3, cats3)
            accuracies.update(acc, batch_size)
            f1_accuracies.update(f1_acc, batch_size)

            print('Epoch: [{0}][{1}/{2}] '
                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '
                  'Elapsed {remain:s} '
                  'Loss: {loss.val:.3f}({loss.avg:.3f}) '
                  'Acc: {acc.val:.3f}({acc.avg:.3f}) '
                  'f1_Acc: {f1_acc.val:.3f}({f1_acc.avg:.3f}) ' 
                  'sent/s {sent_s:.0f} '
                  .format(
                  epoch, step+1, len(data_loader),
                  data_time=data_time, loss=losses,
                  acc=accuracies,
                  f1_acc=f1_accuracies,
                  remain=timeSince(start, float(step+1)/len(data_loader)),
                  sent_s=sent_count.avg/batch_time.avg
                  ))

    return correct_predictions.double() / n_examples, losses.avg

def validate(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):
    model = model.eval()
    losses = []
    correct_predictions = 0
    cnt = 0
    for d in tqdm(data_loader):
        with torch.no_grad():
            input_ids = d["input_ids"].to(device)
            attention_mask = d["attention_mask"].to(device)
            pixel_values = d['pixel_values'].to(device)

            cats3 = d["cats3"].to(device)
            
            outputs3 = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                pixel_values=pixel_values
            )
            _, preds = torch.max(outputs3, dim=1)

            loss3 = loss_fn(outputs3, cats3)
            loss = loss3
#             loss = loss1 * 0.05 + loss2 * 0.1 + loss3 * 0.85

            correct_predictions += torch.sum(preds == cats3)
            losses.append(loss.item())
            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            if cnt == 0:
                cnt +=1
                outputs3_arr = outputs3
                cats3_arr = cats3
            else:
                outputs3_arr = torch.cat([outputs3_arr, outputs3],0)
                cats3_arr = torch.cat([cats3_arr, cats3],0)
    acc,f1_acc = calc_tour_acc(outputs3_arr, cats3_arr)
    return f1_acc, np.mean(losses)

def train(fold):
    # out of fold
    # train 함수가 for 문 돌거니까 fold_split(fold)은 바깥으로 빼자
    
    train = df[df["kfold"] != fold].reset_index(drop=True)
    valid = df[df["kfold"] == fold].reset_index(drop=True)
    # 선언 셀
    tokenizer = AutoTokenizer.from_pretrained("klue/roberta-large", padding_side = 'left')
    feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-large-patch32-384')
    
    train_data_loader = create_data_loader(train, tokenizer, feature_extractor, 256, 16, shuffle_=True)
    valid_data_loader = create_data_loader(valid, tokenizer, feature_extractor, 256, 16)
    
    

    # for 문 밖으로 꺼내야해

    # 모델
    model = TourClassifier(n_classes3 = 128,
                          text_model_name = 'klue/roberta-large',
                          image_model_name = 'google/vit-large-patch32-384'
                          ).to(device)
    # optimizer
    optimizer = optim.AdamW(model.parameters(), lr= 3e-5)
    #step
    total_steps = len(train_data_loader) * EPOCHS
    # scheduler
    scheduler = get_cosine_schedule_with_warmup(optimizer,
                                                num_warmup_steps = int(total_steps*0.1),
                                                num_training_steps = total_steps
                                               )
    
    # fold 전체 돌때 매번 max_acc가 초기화 되면 곤란한데 -> 알아내야해 
    # -> epoch for문에서 어차피 저장이 되네 초기화 해도 상관없다. 나이스
    max_acc = 0
    for epoch in range(EPOCHS):
        print('-' * 20)
        print(f'Epoch {epoch}/{EPOCHS-1} | Fold {fold}/{FOLD-1}')
        print('-' * 20)
        train_acc, train_loss = train_epoch(model,
                                           train_data_loader,
                                           loss_fn,
                                           optimizer,
                                           device,
                                           scheduler,
                                           len(train),
                                           epoch)
        print('start validate |')
        validate_acc, validate_loss = validate(model,
                                               valid_data_loader,
                                               loss_fn,
                                               optimizer,
                                               device,
                                               scheduler,
                                               len(valid)
                                              )
        if epoch > EPOCHS-5 and epoch < EPOCHS:
            # 에폭 - 5 전과 에폭 끝나기 직전은 저장 X -> 속도 올려줄거임
            if validate_acc > max_acc:
                max_acc = validate_acc
                torch.save(model.state_dict(),f'epoch|{epoch}_fold|{fold}.pt')
#         if validate_acc > max_acc:
#             max_acc = validate_acc
#             torch.save(model.state_dict(),f'epoch|{epoch}_fold|{fold}.pt')

        print(f'Train loss {train_loss} accuracy {train_acc}')
        print(f'Validate loss {validate_loss} accuracy {validate_acc}')
        print("")
        print("")

import torch

device = torch.device('mps')

# # 선언 셀
# FOLD_NUM = 5
# tokenizer = AutoTokenizer.from_pretrained("klue/roberta-large")
# feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-large-patch32-384')

# # for 문 밖으로 꺼내야해

# # 모델
# model = TourClassifier(n_classes3 = 128,
#                       text_model_name = 'klue/roberta-large',
#                       image_model_name = 'google/vit-large-patch32-384'
#                       ).to(device)
# # optimizer
# optimizer = optim.AdamW(model.parameters(), lr= 3e-5)


# # loss_fn 정의
# loss_fn = nn.CrossEntropyLoss().to(device)

# train 시작
EPOCHS = 7
# loss_fn 정의
loss_fn = nn.CrossEntropyLoss().to(device)
# fold 나누기
for k in range(FOLD):
    train(k)

"""# Inferrence"""

class CategoryDataset(Dataset):
    def __init__(self, text, image_path, tokenizer, feature_extractor, max_len):
        self.text = text
        self.image_path = image_path
        self.tokenizer = tokenizer
        self.feature_extractor = feature_extractor
        self.max_len = max_len
    def __len__(self):
        return len(self.text)
    def __getitem__(self, item):
        text = str(self.text[item])
        image_path = os.path.join(data_path,str(self.image_path[item])[2:])
        image = cv2.imread(image_path)
        encoding = self.tokenizer.encode_plus(
          text,
          add_special_tokens=True,
          max_length=self.max_len,
          return_token_type_ids=False,
          padding = 'max_length',
          truncation = True,
          return_attention_mask=True,
          return_tensors='pt',
        )
        image_feature = self.feature_extractor(images=image, return_tensors="pt")
        return {
          'input_ids': encoding['input_ids'].flatten(),
          'attention_mask': encoding['attention_mask'].flatten(),
          'pixel_values': image_feature['pixel_values'][0],
        }

def create_data_loader(df, tokenizer, feature_extractor, max_len, batch_size, shuffle_=False):
    ds = CategoryDataset(
        text=df.overview.to_numpy(),
        image_path = df.img_path.to_numpy(),
        tokenizer=tokenizer,
        feature_extractor = feature_extractor,
        max_len=max_len
    )
    return DataLoader(
        ds,
        batch_size=batch_size,
        num_workers=4,
        shuffle = shuffle_
    )

def inference(model,data_loader,device,n_examples):
    model = model.eval()
    preds_arr = []
    preds_arr2 = []
    preds_arr3 = []
    for d in tqdm(data_loader):
        with torch.no_grad():
            input_ids = d["input_ids"].to(device)
            attention_mask = d["attention_mask"].to(device)
            pixel_values = d['pixel_values'].to(device)

            outputs3 = model(    
                input_ids=input_ids,
                attention_mask=attention_mask,
                pixel_values=pixel_values
            )
            _, preds3 = torch.max(outputs3, dim=1)
            preds_arr3.append(preds3.cpu().numpy())

            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
    return preds_arr3

test = pd.read_csv(f'{data_path}test.csv')

tokenizer = AutoTokenizer.from_pretrained("klue/roberta-large", padding_side = 'left')
feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-large-patch32-384')
model = TourClassifier(n_classes3 = 128,
                          text_model_name = 'klue/roberta-large',
                          image_model_name = 'google/vit-large-patch32-384'
                          ).to(device)
eval_data_loader = create_data_loader(test, tokenizer, feature_extractor, 256, 1)

preds_arr3 = inference(
    model,
    eval_data_loader,
    device,
    len(test)
    )

sample_submission = pd.read_csv(f'{data_path}sample_submission.csv')
arr = ['5일장', 'ATV', 'MTB', '강', '게스트하우스', '계곡', '고궁', '고택', '골프', '공연장',
       '공예,공방', '공원', '관광단지', '국립공원', '군립공원', '기념관', '기념탑/기념비/전망대',
       '기암괴석', '기타', '기타행사', '농.산.어촌 체험', '다리/대교', '대중콘서트', '대형서점',
       '도립공원', '도서관', '동굴', '동상', '등대', '래프팅', '면세점', '모텔', '문', '문화관광축제',
       '문화원', '문화전수시설', '뮤지컬', '미술관/화랑', '민물낚시', '민박', '민속마을', '바/까페',
       '바다낚시', '박람회', '박물관', '발전소', '백화점', '번지점프', '복합 레포츠', '분수', '빙벽등반',
       '사격장', '사찰', '산', '상설시장', '생가', '서비스드레지던스', '서양식', '섬', '성',
       '수련시설', '수목원', '수상레포츠', '수영', '스노쿨링/스킨스쿠버다이빙', '스카이다이빙', '스케이트',
       '스키(보드) 렌탈샵', '스키/스노보드', '승마', '식음료', '썰매장', '안보관광', '야영장,오토캠핑장',
       '약수터', '연극', '영화관', '온천/욕장/스파', '외국문화원', '요트', '윈드서핑/제트스키',
       '유람선/잠수함관광', '유명건물', '유스호스텔', '유원지', '유적지/사적지', '이색거리', '이색찜질방',
       '이색체험', '인라인(실내 인라인 포함)', '일반축제', '일식', '자동차경주', '자연생태관광지',
       '자연휴양림', '자전거하이킹', '전문상가', '전시관', '전통공연', '종교성지', '중식', '채식전문점',
       '카약/카누', '카지노', '카트', '컨벤션', '컨벤션센터', '콘도미니엄', '클래식음악회', '클럽',
       '터널', '테마공원', '트래킹', '특산물판매점', '패밀리레스토랑', '펜션', '폭포', '학교', '한식',
       '한옥스테이', '항구/포구', '해수욕장', '해안절경', '헬스투어', '헹글라이딩/패러글라이딩', '호수',
       '홈스테이', '희귀동.식물']

for i in range(len(preds_arr3)):
    sample_submission.loc[i,'cat3'] = arr[preds_arr3[i][0]]

sample_submission.to_csv('brannew_baseline.csv',index=False)

sample_submission

